<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Metareviewer Instructions | ML4H: Machine Learning for Health
</title>
  <meta http-equiv = "refresh" content = "0; url =https://ml4health.github.io/2021/metareviewer-instructions.html" />
  <link rel="canonical" href="../pages/metareviewer-instructions.html">



  <link rel="stylesheet" href="../theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="../theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="../theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="../theme/css/style.css">
  <link rel="stylesheet" href="../theme/css/custom.css">


<meta name="description" content="Questions? Please send any questions to: ml4h.workshop.neurips.2020@gmail.com Goals for Meta-reviewing Process The goal of the meta-reviewing process is fourfold: Summarize the opinions of the reviewers to aid in final decision making. Note that in addition to accept/reject, proceedings track submissions can also be offered …">
</head>

<body>
  <header class="header">
    <div class="container">
      <div class="row">
        <div class="col-xs-2">
          <a href="../">
            <img class="img-fluid" src=../images/logo.png alt="ML4H: Machine Learning for Health">
          </a>
        </div>
        <div class="col-xs-10">
          <h1 class="title"><a href="../">ML4H: Machine Learning for Health</a></h1>
          <ul class="list-inline">
            <li class="list-inline-item"><a href="../pages/call-for-participation.html">Call for Participation</a></li>
            <li class="list-inline-item"><a href="../pages/writing-a-good-ml4h-paper.html">Writing Guidelines</a></li>
            <li class="list-inline-item"><a href="../pages/reviewer-instructions.html">Reviewers</a></li>           
            <li class="list-inline-item"><a href="../pages/mentorship.html">Mentorship</a></li>
            <li class="list-inline-item"><a href="../pages/speakers.html">Speakers</a></li>
            <li class="list-inline-item"><a href="../pages/organizers.html">Organizers</a></li>
          </ul>
        </div>
      </div>
    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>Metareviewer Instructions
</h1>
      <hr>
<article class="article">
  <div class="content">
    <h3>Questions?</h3>
<p>Please send any questions to: ml4h.2021@gmail.com</p>
<h3>Goals for Meta-reviewing Process</h3>
<p>The goal of the meta-reviewing process is fourfold:</p>
<ol>
<li>
<p>Drive the consensus-building discussion period amongst reviewers such that reviewers both
<ul>
<li> Align on an overall recommendation, such that (ideally) all final reviews and meta-reviews present a unified recommendation and aligned set of scores. </li>
  <li> Appropriately consider and address any new information offered in the author response. </li>
</ul>
  </p>
</li>
<li>
<p>Write a meta-review that should:
<ul>
<li> Summarize the opinions of the reviewers to aid in final decision making. </li>
<li> Provide a summary of the reviews’ salient points for the author, focusing specifically on what critical aspects would be needed to improve the submission for acceptance in the future and/or what key strengths led the meta-reviewer to recommend acceptance. </li>
</ul>
</p>
</li>
<li>
<p>Flag low-quality reviews to give reviewers feedback on their review quality.</p>
</li>
<li>
<p>Highlight high-quality papers and reviews for consideration for ML4H’s 2021 Best Thematic Submission, Best Newcomer Submission, and Top Reviewer awards.</p>
</li>
</ol>
<h3>Meta-Reviewing Tasks</h3>
<ol>
<li>
  <p> <b> By October 4th, AoE:</b> Confirm that you are comfortable meta-reviewing all assigned papers.</p>
</li>
<li>
  <p> <b> October 7th: 12:01 a.m. AoE - 5:00 p.m. ET:</b> Examine all reviews submitted across your papers and flag any that should be replaced with an emergency review due to poor quality.</p>
<p> Identifying a review that should be replaced should not in general require reading the paper or forming your own opinion of the work; instead, this is an opportunity to flag reviews that are unambiguously lacking sufficient content to motivate a recommendation (e.g., the review is one sentence, and a score), lacking sufficient expertise to motivate trust (e.g., the reviewer states “I don’t know enough about this to review”), or are incomprehensible or severely inconsistent (e.g., the free-text says that they love the work, with no cons identified, but the score is a strong reject). Flagged reviews will then be replaced by an emergency review from a new reviewer. You can flag these low quality reviews via this form: <a href="https://forms.gle/h5LrN9jZRgLhZGST8">https://forms.gle/h5LrN9jZRgLhZGST8</a>.</p>
</li>
<li>
  <p> <b> October 11th: </b> Examine all submitted reviews and identify any point of disagreement or opportunity for consensus building across your reviewers. Initiate discussion by highlighting these areas to your reviewers in HotCRP, while reminding reviewers that final updates and the full consensus period will occur after the author response is submitted on October 16th.</p>
</li>
<li>
  <p> <b> October 16th - October 20th: </b> Drive the formal discussion period and align reviewers to form updated, consensus reviews for their submissions. Reviewers should confront any inter-reviewer disagreements, respond to any points raised in author rebuttals, and be encouraged to update their scores if other reviewers or authors address previously identified major concerns during this process. The final output of this process should be a set of unified reviews. Note that the intent of this period is not to provide homogenous reviews, but rather to ensure that all reviews improve by taking into account the perspectives of other reviewers and that (insofar as is possible) reviewers can align on a consensus decision.</p>
</li>
<li>
  <p> <b> By October 21st: </b> Complete the meta-review form on HotCRP for each assigned paper. </p>
</li>
<li>
  <p> <b> By October 21st, Proceedings Track Only: </b> Please copy or download this <a href="https://docs.google.com/spreadsheets/d/1Bd-8QdjfG7tJjZdv6kNCNZ5bM87l4iVOS2Se8T05nVk/edit?usp=sharing">spreadsheet template</a>, then fill it in to rank your assigned metareview papers. After you're done, please upload a csv or excel file of your ranking spreadsheet via this form <a href="https://forms.gle/c4ZqUVZ1b5LA45gn9">https://forms.gle/c4ZqUVZ1b5LA45gn9</a>. Come to the Zoom meeting on Oct 22nd prepared to discuss any borderline papers.</p>
</li>
</ol>
<h3>Timeline</h3>
<p>Sep. 13th AoE: Submission deadline. </p>
<p>Sep. 16th:  Reviews & Meta-reviews assigned. Reviewing period begins! </p>
<p>By Oct. 4th: Meta-review Swap Deadline: If you do not feel comfortable meta-reviewing one of your assigned papers, please contact us and we will try to arrange a swap with another meta-reviewer.</p>
<p>Oct. 6th AoE: Review deadline</p>
<p>Oct. 7th: Meta-reviewers examine reviews on their assigned papers to flag problematic reviews that warrant additional emergency reviews; Emergency Reviews Assigned; Emergency Review Period Starts; </p>
    <p> Oct. 10th: Emergency Reviews Due </p>
    <p> Oct. 11th: Meta-reviewers look at reviews & initiate reviewer discussion. <p>
    <p> Oct. 11th AoE: Author Response Period Starts </p>
    <p> Oct. 15th AoE: Author Response Period Ends </p>
    <p> Oct. 16th-20th: Meta-reviewers encourage reviewers to review author response and encourage consensus-speaking reviewer discussion. </p>
    <p> Oct. 21st: Meta-reviews due. Proceedings Track meta-reviewers send rankings to the organizing committee at ml4h.2021@gmail.com. </p>
    <p> Oct 22nd 9-10am ET or 5-6pm ET [Proceedings Track Only] Meta-reviewers attend zoom call to make final decisions. Note there are two meetings serving the same purpose, please come at whichever time you prefer. </p>
    <p> Oct. 27th: Final Decisions Released </p>

    <h3>How do I look at reviews for a paper on HotCRP &amp; write my meta-review?</h3>
<p>After clicking on a paper, make sure that you select "Main" in the upper left hand corner. This will take you to a summary of all of the completed reviews and allow you to post comments and rate reviews. To write your meta-review, click on "Review" in the upper left hand corner.</p>

    <h3>How do I flag reviews as being problematic and requiring emergency reviewer support?</h3>
<p>This process is only available on October 7th, from 8:01 am ET - 5:00 pm ET. Within this time-frame, we ask that you login to HotCRP and check the quality of your reviews to identify any that are egregiously short, unclear, or non-expert (refer to the list of tasks above for a more detailed description of the criteria here). Please fill out this <a href="https://forms.gle/h5LrN9jZRgLhZGST8">form</a> for each review that you think warrants an additional emergency review. In this form, you will refer to each review by its ID (e.g. “83B”) which you can find in HotCRP. The review ID is combined by the paper ID (a number) and a capital letter.  </p>
<p> If you cannot be available in this window to check review quality, please let us know ASAP so we can arrange for your papers to be covered by an external volunteer. </p>
    
    <h3>How do I lead the reviewer discussion period?</h3>
<p>During the reviewer discussion period, please participate/initiate the discussion by clicking “add comment” when you are on the review page for the paper. Make sure to change the visibility of the comment to “Hidden from authors” to only send the comment to the reviewers on the paper.</p>

    <h3>How do I write my meta-review?</h3>
<p>To write your meta-review, once you’ve selected a paper, click on “Review” in the upper left hand corner. This will bring up the meta-review form. Please refer to the goals for the meta-reviewing process for information about the purpose of the meta-review.</p>

    <h3>What counts as a good ML4H Paper/Abstract?</h3>
<p>All meta-reviewers should refer to the <a href="https://ml4health.github.io/2021/pages/writing-guidelines.html">guidelines</a> on how to write a good ML4H paper or extended abstract. The criteria for the proceedings and abstract tracks are distinct -- while both tracks require high quality submissions, the abstract submissions should also be judged on their likelihood to lead to a good discussion at the workshop. Note that works submitted to the Proceedings track can also be considered for the extended abstract track. Reviewers have been instructed to flag any works they think would be a good fit for this during review, which you can use to form your overall recommendation on this point.</p>
<p> In addition to the examples highlighted in the writing guidelines themselves, you may also peruse the full <a href="http://proceedings.mlr.press/v136/">ML4H 2020 proceedings</a> and <a href="https://arxiv.org/html/2011.11554">ML4H 2020 arxiv index</a> (abstract track) to gain a better sense of the works we aim to accept. Note in particular on the proceedings track some of ML4H’s prior most heavily cited works, such as <a href="http://proceedings.mlr.press/v116/jaeger20a.html">Retina U-Net</a> or <a href="http://proceedings.mlr.press/v116/wei20a.html">Generative Image Translation for Data Augmentation in Colorectal Histopathology Images</a> </p>
    
    <h3>Conflict Guidelines & Expertise Alignment</h3>
<p>Please check ASAP that your assigned papers do not represent conflicts of interest and that you feel confident in serving as a meta-reviewer for a paper in this topic area. You should not recognize any paper you are reviewing as work done by someone you work closely with.</p>
<p> If you find a conflict or a paper you are not confident you can meta-review, please report it immediately via email: <a href="mailto:ml4h.2021@gmail.com">ml4h.2021@gmail.com</a> </p>
  
    <h3>Format & Anonymity Guidelines</h3>
<p>Reviewers have been instructed to flag any anonymity violations (our process is fully double-blind) or gross violations of format. Such violations can play a role in your decision making process, but as a general rule we would rather accept a strong work that needs to adjust its formatting slightly, or has a minor, clearly unintentional anonymity violation than reject a work on a technicality.</p>

    <h3>Confidentiality Guidelines</h3>
<p>All aspects of the review process should be confidential. Do not discuss or distribute the submissions or reviews or use any ideas from the submissions in your own work until they are publicly available.</p>

     <h3>Meta-reviewing Quota</h3>
<p>Each meta-reviewer should be assigned approximately 10 submissions. We do not have a budget in place for emergency meta-reviewing, so if you are not confident you can serve in this role for up to 10 submissions, please let us know ASAP and we can find a replacement meta-reviewer instead. Note that the purpose of having meta-reviewers review a larger number of submissions is that decisions can thus be more reflective of the overall pool of submissions.</p>

    <h3>Meta-Reviewer Assignment Process</h3>
<p>Authors labeled each paper with a set of topic areas, and each meta-reviewer was asked to rank their topic areas of expertise. These topic areas are used to assign meta-reviewers to the most relevant papers possible. </p>

    <h3>Shared Submission System with NeurIPS Workshop (Only for Extended Abstracts)</h3>
<p>This year, for the first time, ML4H is piloting a shared submission system by cooperating with the Neurips 2021 workshop “Machine learning from ground truth: New medical imaging datasets for unsolved medical problems” . Under this program, a subset of our extended abstract submissions will have their reviews & meta-reviews forwarded to the decision committee for the “Machine learning from ground truth” workshop for use in that committee’s final decisions as well. As such, it is especially important that your “Key Strengths”, “Key Weaknesses”, and “Overall Summary” are all clear, precise, and not anchored to ML4H’s acceptance rates in general. However, your “Final ML4H Recommendation” will be used solely for ML4H -- you do not need to worry about the decision criteria for the shared submission system NeurIPS workshops. See <a href="https://ml4health.github.io/2022/submission.html">here</a> for more information on this program.</p>
    
    <h3>FAQ</h3>
<ul>
<li>Can meta-reviewers also be authors of papers or extended abstracts?</li>
</ul>
<p>Yes. Though of course a meta-reviewer will not be assigned to review their own papers. That's a conflict of interest.</p>
<ul>
<li>What if I don't have sufficient expertise to review a paper assigned to me?</li>
</ul>
<p>While papers should provide enough background that nearly all meta-reviewers can provide a reasonable meta-review, we understand that occasionally a paper may fall far outside your area of expertise. If this happens, please contact ml4h.2021@gmail.com before September 23rd.
</p>
  </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">


          <li class="list-inline-item"><a href="../categories.html">Categories</a></li>

        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          <a href="https://github.com/ml4health/ml4health.github.io">
          source on github
          </a>
          /
          <a href="https://github.com/getpelican/pelican" target="_blank">powered by Pelican</a>
          /
          <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer>
</body>

</html>
