[{"UID":"A6","abstract":"Electrocardiography (ECG) is an effective and non-invasive diagnostic tool that measures the electrical activity of the heart. Interpretation of ECG signals to detect various abnormalities is a challenging task that requires expertise. Recently, the use of deep neural networks for ECG classification to aid medical practitioners has become popular, but their black box nature hampers clinical implementation. Several saliency-based interpretability techniques have been proposed, but they only indicate the location of important features and not the actual features. We present a novel interpretability technique called qLST, a query-based latent space traversal technique that is able to provide explanations for any ECG classification model. With qLST, we train a neural network that learns to traverse in the latent space of a variational autoencoder trained on a large university hospital dataset with over 800,000 ECGs annotated for 28 diseases. We demonstrate through experiments that we can explain different black box classifiers by generating ECGs through these traversals.","authors":"Melle B. Vessies*, Sharvaree P. Vadgama*, Rutger R. van de Leur, Pieter A. Doevendans, Rutger J. Hassink, Erik Bekkers, Ren\u00e9 van Es","chat_active":"","code_link":"","keywords":"interpretability, latent, ecg","paper_link":"","poster_link":"https://drive.google.com/open?id=1UEBWEu9AA3n-xzPjTrlm7gMMjrjr-F5i","presentation_link":"","title":"Interpretable ECG classification via a query-based latent space traversal (qLST)"},{"UID":"C2","abstract":"Temporal dataset shift associated with changes in healthcare over time is a barrier to deploying machine learning-based clinical decision support systems. Algorithms that learn robust models by estimating invariant properties across time periods for domain generalization and unsupervised domain adaptation might be suitable to proactively mitigate dataset shift. In this study, we characterized the impact of temporal dataset shift on clinical prediction models learned from electronic health records and evaluated domain generalization and unsupervised domain adaptation algorithms on improving model robustness compared with the standard empirical risk minimization. Intensive care unit patients from the MIMIC-IV database were categorized by year groups (2008\u00d02010,2011\u00d02013, 2014\u00d02016 and 2017\u00d02019). Feed-forward neural networks were trained using empirical risk minimization as well as variants of domain generalization and adaptation to predict mortality, long length of stay, sepsis, and invasive ventilation. We observed heterogeneity in the impact of temporal dataset shift across clinical prediction tasks, with the worst impact observed in sepsis prediction. When compared with empirical risk minimization, domain generalization and adaptation algorithms failed to produce more robust models. These findings highlight the difficulty of improving robustness to dataset shift with purely data-driven techniques that do not leverage prior knowledge of the nature of the shift and a need for alternate approaches to preserve model performance overtime in clinical medicine.","authors":"Lin Lawrence Guo, Stephen R Pfohl, Jason Fries, Alistair Johnson, Jose Posada, Catherine Aftandilian, Nigam Shah, Lillian Sung","chat_active":"","code_link":"","keywords":"robustness, ehr","paper_link":"","poster_link":"https://drive.google.com/open?id=1zTUYSU-bKIWpcMCnDBR6e7ZMjkanjOxK","presentation_link":"","title":"Evaluation of Domain Generalization and Adaptation on Improving Model Robustness to Temporal Dataset Shift in Clinical Medicine"},{"UID":"A4","abstract":"This work aims to understand the impact of class imbalance on the performance of chest x-ray classifiers, in light of the standard evaluation practices adopted by researchers in terms of discrimination and calibration performance. Firstly, we conducted a literature study to analyze common scientific practices and confirmed that: (1) even when dealing with highly imbalanced datasets, the community tends to use metrics that are dominated by the majority class; and (2) it is still uncommon to include calibration studies for chest x-ray classifiers, albeit its importance in the context of healthcare. Secondly, we perform a systematic experiment on two major chest x-ray datasets to explore the behavior of several performance metrics under different class ratios and show that widely adopted metrics can conceal the performance in the minority class. Finally, we propose the adoption of two alternative metrics, the precision-recall curve and the Balanced Brier score, which better reflect the performance of the system in such scenarios. Our results indicate that current evaluation practices adopted by the research community for chest x-ray classifiers may not reflect the performance of such systems for computer aided diagnosis in real clinical scenarios, and suggest alternatives to improve this situation.","authors":"Candelaria Mosquera, Luciana Ferrer, Diego H. Milone, Daniel Luna, Enzo Ferrante","chat_active":"","code_link":"","keywords":"imaging, fairness","paper_link":"","poster_link":"https://drive.google.com/open?id=1RMXnHtWyDpbFNSsnS-P-5S47o--eFGvo","presentation_link":"","title":"Understanding the impact of class imbalance on the performance of chest x-ray image classifiers"},{"UID":"A5","abstract":"One of the symptoms observed in the early stages of Parkinson's Disease (PD) is speech impairment. Speech disorders can be used to detect this disease before it degenerates. This work analyzes speech features and machine learning approaches to predict PD. Acoustic features such as shimmer and jitter variants, and Mel Frequency Cepstral Coefficients (MFCC) are extracted from speech signals. We use two datasets in this work: the MDVR-KCL and Italian Parkinson\u00d5s Voice and Speech database. To separate PD and non-PD speech signals, seven classification models were implemented: K-Nearest Neighbor, Decision Trees, Support Vector Machines, Naive Bayes, Logistic Regression, Gradient Boosting, Random Forests. Three feature sets were used for each of the models: (a) Acoustic features only, (b) All the acoustic features and MFCC, (c) Selected subset of features from acoustic features and MFCC. Using all the acoustic features and MFCC, together with SVM produced the highest performance with an accuracy of 98% and F1-Score of 99%. When compared with prior art, this shows a better performance. Our code and related documentation is available in a public domain repository.","authors":"Adedolapo Aishat Toye, Suryaprakash Kompalli","chat_active":"","code_link":"","keywords":"parkinson's, nlp","paper_link":"","poster_link":"https://drive.google.com/open?id=1l2k5G3yR5Gvckl2aPN_ndUS-C1LJwLVx","presentation_link":"","title":"Comparative Study of Speech Analysis Methods to Predict Parkinson's Disease"},{"UID":"C1","abstract":"EHR systems lack a unified code system forrepresenting medical concepts, which acts asa barrier for the deployment of deep learningmodels in large scale to multiple clinics and hos-pitals. To overcome this problem, we introduceDescription-based Embedding,DescEmb, a code-agnostic representation learning framework forEHR. DescEmb takes advantage of the flexibil-ity of neural language understanding models toembed clinical events using their textual descrip-tions rather than directly mapping each event toa dedicated embedding. DescEmb outperformedtraditional code-based embedding in extensiveexperiments, especially in a zero-shot transfertask (one hospital to another), and was able totrain a single unified model for heterogeneousEHR datasets.","authors":"Kyunghoon Hur*, Jiyoung Lee*, Jungwoo Oh, Wesley Price, Young-Hak Kim, Edward Choi","chat_active":"","code_link":"","keywords":"robustness, ehr, nlp","paper_link":"","poster_link":"https://drive.google.com/open?id=1x2TfcAYXP121RiTBs4MZotVjNB5liL2X","presentation_link":"","title":"Unifying Heterogenous Electronic Health Records Systems via Text-Based Code Embedding"},{"UID":"E6","abstract":"Control strategies for active prostheses/orthoses use sensor inputs to recognize the user\u00d5s locomotive intention and generate corresponding control commands for producing the desired locomotion. In this paper, we propose a learning-based shared model for predicting ankle-joint motion for different locomotion modes like level-ground walking, stair ascent, stair descent, slope ascent, and slope descent without the need to classify between them. Features extracted from hip and knee joint angular motion are used to continuously predict the ankle angles and moments using a Feed-Forward Neural Network-based shared model. We show that the shared model is adequate for predicting the ankle angles and moments for different locomotion modes without explicitly classifying between the modes. The proposed strategy shows the potential for devising a high-level controller for an intelligent prosthetic ankle that can adapt to different locomotion modes.","authors":"Sharmita Dey, Sabri Boughorbel, Arndt F. Schilling","chat_active":"","code_link":"","keywords":"","paper_link":"","poster_link":"https://drive.google.com/open?id=14njtxDJ8lIj39eISDLQ43-QuV3L9_zw6","presentation_link":"","title":"Learning a Shared Model for Motorized Prosthetic Joints to Predict Ankle-Joint Motion"},{"UID":"B2","abstract":"Bayesian deep learning seeks to equip deep neural networks with the ability to precisely quantify their predictive uncertainty, and has promised to make deep learning more reliable for safety-critical real-world applications. Yet, existing Bayesian deep learning methods fall short of this promise; new methods continue to be evaluated on unrealistic test beds that do not reflect the complexities of the downstream real-world tasks that would benefit most from reliable uncertainty quantification. We propose a set of real-world tasks that accurately reflect such complexities and assess the reliability of predictive models in safety-critical scenarios. Specifically, we curate two publicly available datasets of high-resolution human retina images exhibiting varying degrees of diabetic retinopathy, a medical condition that can lead to blindness, and use them to design a suite of automated diagnosis tasks that require reliable predictive uncertainty quantification. We use these tasks to benchmark well-established and state-of-the-art Bayesian deep learning methods on task-specific evaluation metrics. We provide an easy-to-use codebase for fast and easy benchmarking following reproducibility and software design principles.","authors":"Neil Band*, Tim G. J. Rudner*, Qixuan Feng, Angelos Filos, Zachary Nado, Michael W. Dusenberry, Ghassen Jerfel, Dustin Tran, Yarin Gal","chat_active":"","code_link":"","keywords":"imaging, uncertainty","paper_link":"","poster_link":"https://drive.google.com/open?id=1YZClNI6MJsHVMSb3PdSBnvI1jQPb4vEB","presentation_link":"","title":"Benchmarking Bayesian Deep Learning on Diabetic Retinopathy Detection Tasks"},{"UID":"B6","abstract":"Vast quantities of person-generated health data (wearables) are collected but the process of annotating to feed to machine learning models is impractical. This paper discusses ways in which self-supervised approaches that use contrastive losses, such as SimCLR and BYOL, previously applied to the vision domain, can be applied to high-dimensional health signals for downstream classification tasks of various diseases spanning sleep, heart, and metabolic conditions. To this end, we adapt the data augmentation step and the overall architecture to suit the temporal nature of the data (wearable traces) and evaluate on 5 downstream tasks by comparing other state-of-the-art methods including supervised learning and an adversarial unsupervised representation learning method. We show that SimCLR outperforms the adversarial method and a fully-supervised method in the majority of the downstream evaluation tasks, and that all self-supervised methods outperform the fully-supervised methods. This work provides a comprehensive benchmark for contrastive methods applied to the wearable time-series domain, showing the promise of task-agnostic representations for downstream clinical outcomes.","authors":"Kevalee Shah, Dimitris Spathis, Chi I. Tang, Cecilia Mascolo","chat_active":"","code_link":"","keywords":"wearables, timeseries","paper_link":"","poster_link":"https://drive.google.com/open?id=1lG9wTLphE0AZALUoZGGTA3iVj8ezoDrA","presentation_link":"","title":"Evaluating Contrastive Learning on Wearable Timeseries for Downstream Clinical Outcomes"},{"UID":"C5","abstract":"Simulators make unique benchmarks for causal effect estimation since they do not rely on unverifiable assumptions or the ability to intervene on real-world systems, but are often too simple to capture important aspects of real applications. We propose a simulator of Alzheimer\u00d5s disease aimed at modeling intricacies of healthcare data while enabling benchmarking of causal effect and policy estimators. We fit the system to the Alzheimer\u00d5s Disease Neuroimaging Initiative (ADNI) dataset and ground hand-crafted components in results from comparative treatment trials and observational treatment patterns. The simulator includes parameters which alter the nature and difficulty of the causal inference tasks, such as latent variables, effect heterogeneity, length of observed history, behavior policy and sample size. We use the simulator to compare estimators of average and conditional treatment effects.","authors":"Newton Mwai Kinyanjui*, Fredrik D. Johansson*","chat_active":"","code_link":"","keywords":"causality","paper_link":"","poster_link":"https://drive.google.com/open?id=1XHXwgq_7Rqws1G_VEf8jUOZUFXq3pJ_f","presentation_link":"","title":"ADCB: An Alzheimer's disease benchmark for evaluating observational estimators of causal effects"},{"UID":"D5","abstract":"The development of neural networks for clinical artificial intelligence (AI) is reliant on interpretability, transparency, and performance. The need to delve into the black-box neural network and derive interpretable explanations of model output is paramount. A task of high clinical importance is predicting the likelihood of a patient being readmitted to hospital in the near future to enable efficient triage. With the increasing adoption of electronic health records (EHRs), there is great interest in applications of natural language processing (NLP) to clinical free-text contained within EHRs. In this work, we apply InfoCal the current state-of-the-art model that produces extractive rationales for its predictions, to the task of predicting hospital readmission using hospital discharge notes. We compare extractive rationales produced by InfoCal to competitive transformer-based models pretrained on clinical text data and for which the attention mechanism can be used for interpretation. We find each presented model with selected interpretability or feature importance methods yield varying results, with clinical language domain expertise and pretraining critical to performance and subsequent interpretability.","authors":"Niall Taylor, Lei Sha, Dan W Joyce, Alejo Nevado-Holgado, Thomas Lukasiewicz, Andrey Kormilitzin","chat_active":"","code_link":"","keywords":"nlp, ehr, interpretability, attention","paper_link":"","poster_link":"https://drive.google.com/open?id=103PbQ_FGRZ1Xl6j_P0ZgJEqk_X9pCRg4","presentation_link":"","title":"Rationale production to support clinical decision-making"},{"UID":"B5","abstract":"Literature on machine learning (ML) for multiple sclerosis (MS) has primarily focused on using neuroimaging data such as MRI and clinical laboratory tests for disease identification. However studies have shown that these modalities are not consistent with disease activity such as symptoms or disease progression. Furthermore the cost of collecting data from these modalities is high, leading to scarce evaluations. In this work, we used multi-dimensional and affordable physical and smartphone-based performance outcome measures (POMs) and demographic data to predict multiple sclerosis disease progression. We perform a benchmarking exercise on two datasets (MSOAC and Floodlight) and present results across 8 endpoints and 6 ML models. Our results show that it is possible to predict disease progression using POMs for both a clinical and non-clinical dataset, in the absence of neuroimaging data or clinical laboratory tests.","authors":"Subhrajit Roy*, Diana Mincu*, Negar Rostamzadeh, Chintan Ghate, Nenad Tomasev, Jessica Schrouff, Natalie Harris, Christina Chen, Fletcher Lee Hartsell, Katherine Heller.","chat_active":"","code_link":"","keywords":"wearbles, timeseries","paper_link":"","poster_link":"https://drive.google.com/open?id=1zt8eb8iYDYC17OMEBoza5romw6FsGfLw","presentation_link":"","title":"Disability prediction in multiple sclerosis using performance outcome measures and demographic data"},{"UID":"G1","abstract":"Owing to its pristine soft-tissue contrast and high resolution, structural magnetic resonance imaging (MRI) is widely applied in neurology, making it a valuable data source for image- based machine learning (ML) and deep learning applications. The physical nature of MRI acquisition and reconstruction, however, causes variations in image intensity, resolution, and signal-to-noise ratio. Since ML models are sensitive to such variations, performance on out-of-distribution data, which is inherent to the setting of a deployed healthcare ML application, typically drops below acceptable levels. We propose an interpretability aware adversarial training regime to improve robustness against out-of-distribution samples originating from different MRI hardware. The approach is applied to 1.5T and 3T MRIs obtained from the Alzheimer\u00d5s Disease Neuroimaging Initiative database. We present preliminary results showing promising performance on out-of-distribution samples.","authors":"Merel Kuijs, Catherine R. Jutzeler, Bastian Rieck, Sarah C. Brueningk","chat_active":"","code_link":"","keywords":"imaging, robustness","paper_link":"","poster_link":"https://drive.google.com/open?id=1HHbJE_lZOK8g_RhFEbMJ0eCv6BNXFNF2","presentation_link":"","title":"Interpretability Aware Model Training to Improve Robustness against OOD Magnetic Resonance Images in Alzheimer's Disease Classification"},{"UID":"F6","abstract":"Data-driven models for glucose level forecast often do not provide meaningful insights despite accurate predictions. Yet, context understanding in medicine is crucial, in particular for diabetes management. In this paper, we introduce HAD-Net: a hybrid model that distills knowledge into a deep neural network from physiological models. It models glucose, insulin and carbohydrates diffusion through a biologically inspired deep learning architecture tailored with a recurrent attention network constrained by ODE expert models. We apply HAD-Net for glucose level forecast of patients with type-2 diabetes. It achieves competitive performances while providing plausible measurements of insulin and carbohydrates diffusion over time.","authors":"Quentin Blampey, Mehdi Rahim","chat_active":"","code_link":"","keywords":"attention, ODEs","paper_link":"","poster_link":"https://drive.google.com/open?id=141lsqrD5Xqdgg8cqCGtu_1Jsdg239OT4","presentation_link":"","title":"HAD-Net: Hybrid Attention-based Diffusion Network for Glucose Level Forecast"},{"UID":"G2","abstract":"Medical AI algorithms can often experience degraded performance when evaluated on previously unseen sites. Addressing cross-site performance disparities is key to ensuring that AI is equitable and effective when deployed on diverse patient populations. Multi-site evaluations are key to diagnosing such disparities as they can test algorithms across a broader range of potential biases such as patient demographics, equipment types, and technical parameters. However, such tests do not explain why the model performs worse. Our framework provides a method for quantifying the marginal and cumulative effect of each type of bias on the overall performance difference when a model is evaluated on external data. We demonstrate its usefulness in a case study of a deep learning model trained to detect the presence of pneumothorax, where our framework can help explain up to 60% of the discrepancy in performance across different sites with known biases like disease comorbidities and imaging parameters.","authors":"Eric Wu*, Kevin Wu*, James Zou","chat_active":"","code_link":"","keywords":"robustness, imaging","paper_link":"","poster_link":"https://drive.google.com/open?id=1s8U33ZJWE0jACe-JvAyqDlImnDZSGpYz","presentation_link":"","title":"Explaining medical AI performance disparities across sites with confounder Shapley value analysis"},{"UID":"H2","abstract":"Medical conversation summarization is integral in capturing information gathered during interactions between patients and physicians. Summarized conversations are used to facilitate patient hand-offs between physicians, and as part of providing care in the future. Summaries, however, can be time-consuming to produce and require domain expertise. Modern pre-trained NLP models such as PEGASUS have emerged as capable alternatives to human summarization, reaching state-of-the-art performance on many summarization benchmarks. However, many downstream tasks still require at least moderately sized datasets to achieve satisfactory performance. In this work we (1) explore the effect of dataset size on transfer learning medical conversation summarization using PEGASUS and (2) evaluate various iterative labeling strategies in the low-data regime, following their success in the classification setting. We find that model performance saturates with increase in dataset size and that the various active-learning strategies evaluated all show equivalent performance consistent with simple dataset size increase. We also find that naive iterative pseudo-labeling is on-par or slightly worse than no pseudo-labeling. Our work sheds light on the successes and challenges of translating low-data regime techniques in classification to medical conversation summarization and helps guides future work in this space. Relevant code available at https://github.com/curai/curai-research/tree/main/medical-summarization-ML4H-2021","authors":"Varun Nair*, Namit Katariya, Xavier Amatriain, Ilya Valmianski, Anitha Kannan","chat_active":"","code_link":"","keywords":"pre-training, nlp, data","paper_link":"","poster_link":"https://drive.google.com/open?id=1ahcj9T1B_ZUhMJd1HSi1EwTcF9533Xsk","presentation_link":"","title":"Adding more data does not always help: A study in medical conversation summarization with PEGASUS"},{"UID":"C6","abstract":"Functional networks characterize the coordinated neural activity observed by functional neuroimaging. The prevalence of different networks during resting state periods provide useful features for predicting the trajectory of neurodegenerative diseases. Techniques for network estimation rely on statistical correlation or dependence between voxels. Due to the large number of voxels, rather than consider the voxel-to-voxel correlations between all voxels, a small set of seed voxels are chosen. Consequently, the network identification may depend on the selected seeds. As an alternative, we propose to fit first-order linear models with sparse priors on the coefficients to model activity across the entire set of cortical grey matter voxels as a linear combination of a smaller subset of voxels. We propose a two-stage algorithm for voxel subset selection that uses different sparsity-inducing regularization approaches to identify subject-specific causally predictive voxels. To reveal the functional networks among these voxels, we then apply independent component analysis (ICA) to model these voxels' signals as a mixture of latent sources each defining a functional network. Based on the inter-subject similarity of the sources' spatial patterns we identify independent sources that are well-matched across subjects but fail to match the independent sources from a group-based ICA. These are resting state networks, common across subjects that group ICA does not reveal. These complementary networks could help to better identify neurodegeneration, a task left for future work.","authors":"Hassan Baker, Austin J. Brockmeier","chat_active":"","code_link":"","keywords":"imaging, causality","paper_link":"","poster_link":"https://drive.google.com/open?id=1yMFo3kgPu9ODKneqmhpkklIuGFlWJHKn","presentation_link":"","title":"Exploring latent networks in resting-state fMRI using voxel-to-voxel causal modeling feature selection"},{"UID":"G5","abstract":"Discovering distinct features and their relations from data can help us uncover valuable knowledge crucial for various tasks, e.g., classification. In neuroimaging, these features could help to understand, classify, and possibly prevent brain disorders. Model introspection of highly performant overparameterized deep learning (DL) models could help find these features and relations. However, to achieve high-performance level DL models require numerous labeled training samples (n) rarely available in many fields. This paper presents a pre-training method involving graph convolutional/neural networks (GCNs/GNNs), based on maximizing mutual information between two high-level embeddings of an input sample. Many of the recently proposed pre-training methods pre-train one of many possible networks of an architecture. Since almost every DL model is an ensemble of multiple networks, we take our high-level embeddings from two different networks of a model --a convolutional and a graph network--. The learned high-level graph latent representations help increase performance for downstream graph classification tasks and bypass the need for a high number of labeled data samples. We apply our method to a neuroimaging dataset for classifying subjects into healthy control (HC) and schizophrenia (SZ) groups. Our experiments show that the pre-trained model significantly outperforms the non-pre-trained model and requires 50% less data for similar performance.","authors":"Usman Mahmood, Zening Fu, Vince Calhoun, Sergey Plis","chat_active":"","code_link":"","keywords":"pre-training, imaging, GNNs, neuro","paper_link":"","poster_link":"https://drive.google.com/open?id=19_MYwDV0l00STcve1A5jLjIy0fU0Krui","presentation_link":"","title":"Multi network InfoMax: A pre-training method involving graph convolutional networks"},{"UID":"H3","abstract":"We investigate the potential of machine learning models for the prediction of visual improvement after macular hole surgery from preoperative data (retinal images and clinical features). Collecting our own data for the task, we end up with only 121 total samples, putting our work in the very limited data regime. We explore a variety of deep learning methods for limited data to train deep computer vision models, finding that all tested deep vision models are outperformed by a simple regression model on the clinical features.We believe this is compelling evidence of the extreme difficulty of using deep learning on very limited data.","authors":"Mathieu Godbout, Alexandre Lachance, Fares Antaki, Ali Dirani, Audrey Durand","chat_active":"","code_link":"","keywords":"imaging, data","paper_link":"","poster_link":"https://drive.google.com/open?id=1LtP7oziOp_zccOlcGllxUo_fNvuiu5Of","presentation_link":"","title":"Predicting Visual Improvement after Macular Hole Surgery: a Cautionary Tale on Deep Learning with Very Limited Data"},{"UID":"G6","abstract":"Multivariate dynamical processes can often be intuitively described by a weighted connectivity graph between components representing each individual time-series. Even a simple representation of this graph as a Pearson correlation matrix may be informative and predictive as demonstrated in the brain imaging literature. However, there is a consensus expectation that powerful graph neural networks (GNNs) should perform better in similar settings. In this work we present a model that is considerably shallow than deep GNNs, yet outperforms them in predictive accuracy in a brain imaging application. Our model learns the autoregressive structure of individual time series and estimates directed connectivity graphs between the learned representations via a self-attention mechanism in an end-to-end fashion. The supervised training of the model as a classifier between patients and controls results in a model that generates directed connectivity graphs and highlights the components of the time-series that are predictive for each subject. We demonstrate our results on a functional neuroimaging dataset classifying schizophrenia patients and controls.","authors":"Usman Mahmood, Zening Fu, Vince Calhoun, Sergey Plis","chat_active":"","code_link":"","keywords":"attention, neuro","paper_link":"","poster_link":"https://drive.google.com/open?id=1Kun3HYMhd-yPpS7FVWYgbUvrAeb7uiSF","presentation_link":"","title":"Brain dynamics via Cumulative Auto-Regressive Self-Attention"},{"UID":"E5","abstract":"Significant advancements have been made in recent years to optimize patient recruitment for clinical trials, however, improved methods for patient recruitment prediction are needed to support trial site selection and to estimate appropriate enrollment timelines in the trial design stage. In this paper, using data from thousands of historical clinical trials, we explore machine learning methods to predict the number of patients enrolled per month at a clinical trial site over the course of a trial's enrollment duration. We show that these methods can reduce the error that is observed with current industry standards and propose opportunities for further improvement.","authors":"Jingshu Liu*, Patricia J. Allen*, Luke Benz, Daniel Blickstein, Evon Okidi, Xiao Shi","chat_active":"","code_link":"","keywords":"clinical trials","paper_link":"","poster_link":"https://drive.google.com/open?id=1oY3qCPh35Lg3EYxUIDuk8mNouqrBHpL3","presentation_link":"","title":"A Machine Learning Approach for Recruitment Prediction in Clinical Trial Design"},{"UID":"H6","abstract":"Deep learning models have reached or surpassed human-level performance in the field of medical imaging, especially in disease diagnosis using chest x-rays. However, prior work has found that such classifiers can exhibit biases in the form of gaps in predictive performance across protected groups. In this paper, we benchmark the performance of nine methods in improving the fairness of these classifiers. We utilize the minimax definition of fairness, which focuses on maximizing the performance of the worst-case group. Our experiments show that certain methods are able to improve worst-case performance for selected metrics and protected attributes. However, we find that the magnitude of such gains is limited. Finally, we provide best practices for selecting fairness definitions for use in the clinical setting.","authors":"Haoran Zhang, Natalie Dullerud, Karsten Roth, Stephen Pfohl, Marzyeh Ghassemi","chat_active":"","code_link":"","keywords":"fairness, imaging","paper_link":"","poster_link":"https://drive.google.com/open?id=1JFxKArLBFn_PWPOKkJQw-sWn6hznwc-I","presentation_link":"","title":"Improving the Fairness of Deep Chest X-ray Classifiers"},{"UID":"H1","abstract":"More than 3 billion people lack access to care for skin disease. AI diagnostic tools may aid in early skin cancer detection; however, most models have not been assessed on images of diverse skin tones or uncommon diseases. To address this, we curated the Diverse Dermatology Images (DDI) dataset\u00d1the first publicly available, pathologically confirmed images featuring diverse skin tones. We show that state-of-the-art dermatology AI models perform substantially worse on DDI, with ROC-AUC dropping 29-40 percent compared to the models\u00d5 original results. We find that dark skin tones and uncommon diseases, which are well represented in the DDI dataset, lead to performance drop-offs. Additionally, we show that state-of-the-art robust training methods cannot correct for these biases without diverse training data. Our findings identify important weaknesses and biases in dermatology AI that need to be addressed to ensure reliable application to diverse patients and across all diseases.","authors":"Roxana Daneshjou*, Kailas Vodrahalli*, Weixin Liang*, Roberto A Novoa, Melissa Jenkins, Veronica Rotemberg, Justin Ko, Susan M Swetter, Elizabeth E Bailey, Olivier Gevaert, Pritam Mukherjee, Michelle Phung, Kiana Yekrang, Bradley Fong, Rachna Sahasrabudhe, Albert Chiou, James Zou","chat_active":"","code_link":"","keywords":"imaging, robustness","paper_link":"","poster_link":"https://drive.google.com/open?id=1gbcJ3yXa03b6A2U6fdR6ai_MtQaB5U6B","presentation_link":"","title":"Disparities in Dermatology AI: Assessments Using Diverse Clinical Images"},{"UID":"F1","abstract":"Prostate cancer is the second most common cancer among men worldwide. For prognosis and treatment, pathologists assign International Society of Urological Pathology (ISUP) grades to Whole Slide Imaging (WSI) of sampled prostate tissues to express the severity of the cancer. The manual approach suffers from human error and person-to-person variations. Existing approaches that use machine learning for automatic grading of WSI images includes using expensive datasets in which different regions of the slide are annotated by pathologists to show different levels of cancer. However, most of the existing real-world datasets contain weak labels; i.e. each slide is labeled with just one grade number. In this work, we present a self-supervised learning method to automatically grade prostate slides using datasets of weakly labeled slides.","authors":"Amirata Ghorbani, Andre Esteva, James Zou","chat_active":"","code_link":"","keywords":"self-supervision, pre-training","paper_link":"","poster_link":"https://drive.google.com/open?id=1n0KuF2NrliUrq2EfxFmq9UBOW7_mBqo4","presentation_link":"","title":"Grading of Prostate Whole-slide Images Using Weak Self-supervised Learning"},{"UID":"H5","abstract":"Cortical thickness and functional connectivity are two parallel approaches that have been widely used to gain insights into psychotic disorders. Significant abnormalities in these modalities, even at the early stage of psychosis, have been shown in the literature. However, few have studied them together or explored the influences of functional connectivity on cortical thickness networks. Prior studies using gyral-based atlases reported that cortical thickness regions susceptible to thickness reductions are strongly interconnected and that brain tissue volume loss in schizophrenia is conditioned by structural and functional connectivity. With data-driven approaches, we assessed: 1) How are cortical thickness networks organized, functionally or structurally? 2) What features drive this organization, and do features vary by diagnosis? 3) What are the relationships between cortical thickness reductions and clinical assessments?","authors":"Kristina M. Holton*, Shi Yu Chan*, Austin J. Brockmeier, Dost \u00d6ng\u00fcr, Mei-Hua Hallk","chat_active":"","code_link":"","keywords":"neuro","paper_link":"","poster_link":"https://drive.google.com/open?id=1InJsg-AM_vi2Ml-L41YXwajzPMT5sXp7","presentation_link":"","title":"Exploring the influences of functional connectivity architecture on cortical thickness networks in patients with early psychosis"},{"UID":"G3","abstract":"Human medical data can be challenging to obtain due to data privacy concerns, difficulties conducting certain types of experiments, or prohibitive associated costs. In many settings, data from animal models or in-vitro cell lines are available to help augment our understanding of human data. However, this data is known for having low etiological validity in comparison to human data. In this work, we augment small human medical datasets with in-vitro data and animal models. We use Invariant Risk Minimisation (IRM) to elucidate invariant features by considering cross-organism data as belonging to different data-generating environments. Our models identify genes of relevance to human cancer development. We observe a degree of consistency between varying the amounts of human and mouse data used, however, further work is required to obtain conclusive insights. As a secondary contribution, we enhance existing open source datasets and provide two uniformly processed, cross-organism, homologue gene-matched datasets to the community.","authors":"Odhran O'Donoghue, Paul Duckworth, Giuseppe Ughi, Linus Scheibenreif, Kia Khezeli, Adrienne Hoarfrost, Samuel Budd, Patrick Foley, Nicholas Chia, John Kalantari, Graham Mackintosh, Frank Soboczenski, Lauren Sanders","chat_active":"","code_link":"","keywords":"causality, robustness","paper_link":"","poster_link":"https://drive.google.com/open?id=1MRaTUcupQSZ-6n9OT-pNNAn2JK7FDtzo","presentation_link":"","title":"Invariant Risk Minimisation for Cross-Organism Inference: Substituting Mouse Data for Human Data in Human Risk Factor Discovery"},{"UID":"D1","abstract":"Dementia is a neurodegenerative disorder that causes cognitive decline and affects more than 50 million people worldwide. Dementia is under-diagnosed by healthcare professionals - only one in four people who suffer from dementia are diagnosed. Even when a diagnosis is made, it may not be entered as a structured International Classification of Diseases (ICD) diagnosis code in a patient's charts. Information relevant to cognitive impairment (CI) is often found within electronic health records (EHR), but manual review of clinician notes by experts is both time consuming and often prone to errors. Automated mining of these notes presents an opportunity to label patients with cognitive impairment in EHR data. We developed natural language processing (NLP) tools to identify patients with cognitive impairment and demonstrate that linguistic context enhances performance for the cognitive impairment classification task. We fine-tuned our attention based deep learning model, which can learn from complex language structures, and substantially improved accuracy (0.93) relative to a baseline NLP model (0.84). Further, we show that deep learning NLP can successfully identify dementia patients without dementia-related ICD codes or medications.","authors":"Tanish Tyagi*, Colin G. Magdamo*, Ayush Noori, Zhaozhi Li, Xiao Liu, Mayuresh Deodhar, Zhuoqiao Hong, Wendong Ge, Elissa M. Ye, Yi-han Sheu, Haitham Alabsi,Laura Brenner, Gregory K. Robbins, Sahar Zafar, Nicole Benson, Lidia Moura, John Hsu, Alberto Serrano-Pozo, Dimitry Prokopenko, Rudolph E. Tanzi, Bradley T.Hyman, Deborah Blacker, Shibani S. Mukerji, M. Brandon Westover, Sudeshna Das","chat_active":"","code_link":"","keywords":"nlp, ehr, attention","paper_link":"","poster_link":"https://drive.google.com/open?id=1c5Rj_k49-w54Xe9WtYMBMz40j1K0XPmn","presentation_link":"","title":"Using Deep Learning to Identify Patients with Cognitive Impairment in Electronic Health Records"},{"UID":"D2","abstract":"Detection of Out-of-Distribution (OOD) samples in real time is a crucial safety check for deployment of machine learning models in the medical field. Despite a growing number of uncertainty quantification techniques, there is a lack of evaluation guidelines on how to select OOD detection methods in practice. This gap impedes implementation of OOD detection methods for real-world applications. Here, we propose a series of practical considerations and tests to choose the best OOD detector for a specific medical dataset. These guidelines are illustrated on a real-life use case of Electronic Health Records (EHR). Our results can serve as a guide for implementation of OOD detection methods in clinical practice, mitigating risks associated with the use of machine learning models in healthcare.","authors":"Karina Zadorozhny, Patrick Thoral, Paul Elbers, Giovanni Cin\u00e0","chat_active":"","code_link":"","keywords":"uncertainty, robustness, ehr","paper_link":"","poster_link":"https://drive.google.com/open?id=1Pe6bpjrVSQnGTC0yIhoDL7a8Np5HCBkv","presentation_link":"","title":"Out-of-Distribution Detection for Medical Applications: Guidelines for Practical Evaluation"},{"UID":"B1","abstract":"The integration of artificial intelligence into clinical workflows requires reliable and robust models. Among the main features of robustness is repeatability. Much attention is given to classification performance without assessing the model repeatability, leading to the development of models that turn out to be unusable in practice. In this work, we evaluate the repeatability of four model types on images from the same patient that were acquired during the same visit. We study the performance of binary, multi-class, ordinal, and regression models on three medical image analysis tasks: cervical cancer screening, breast density estimation, and retinopathy of prematurity classification. Moreover, we assess the impact of sampling Monte Carlo dropout predictions at test time on classification performance and repeatability. Leveraging Monte Carlo predictions significantly increased repeatability for all tasks on the binary, multi-class, and ordinal models leading to an average reduction of the 95% limits of agreement by 17% points.","authors":"Andreanne Lemay, Katharina Hoebel, Christopher P. Bridge, Didem Egemen, Ana Cecilia Rodriguez, Mark Schiffman, John Peter Campbell, Jayashree Kalpathy-Cramer","chat_active":"","code_link":"","keywords":"imaging, uncertainty","paper_link":"","poster_link":"https://drive.google.com/open?id=11oSPG6ftfe-83PFRszC1Qj-B1IFwgj7B","presentation_link":"","title":"Monte Carlo dropout increases model repeatability"},{"UID":"B4","abstract":"Machine learning (ML) approaches have shown promising results in a variety of healthcare applications. Data plays a vital role in the development of ML-based healthcare systems that directly impact human lives. Many of the ethical issues with healthcare applications of ML can be traced back to structural inequalities that are reflected in the way we collect and process data. Developing a guideline for improving documentation practices in the creation, use and maintenance of ML healthcare datasets is of critical importance. In this work, we introduce Healthsheet, to address adaptations and expansions of the original datasheet questionnaire to healthcare-specific applications. We address the collection and use of sensitive attributes, dataset versioning and maintenance, privacy, data collection context, and health-related devices. As part of the development process of Healthsheet, we worked with three publicly-available healthcare datasets as our case studies, each with different types of structured data: Electronic Health Records (EHR), multiple sclerosis (MS) clinical trial data and smartphone-based performance outcome measures.","authors":"Negar Rostamzadeh, Subhrajit Roy, Diana Mincu, Andrew Smart, Lauren Wilcox, Mahima Pushkarna, Razvan Amironesei, Jessica Schrouff, Madeleine Elish, Nyalleng Moorosi, Berk Ustun, Noah Broesti, Katherine Heller","chat_active":"","code_link":"","keywords":"fairness","paper_link":"","poster_link":"https://drive.google.com/open?id=1Sc9z_w4Ej0cqPI_2ZAI50Uac_Cw3l68B","presentation_link":"","title":"Specialized Healthsheet for Healthcare Datasets"},{"UID":"E4","abstract":"Mechanical ventilation is one of the most widely used therapies in the ICU. However, despite broad application from anaesthesia to COVID-related life support, many injurious challenges remain. We frame these as a control problem: ventilators must let air in and out of the patient's lungs according to a prescribed trajectory of airway pressure. Industry-standard controllers, based on the PID method, are neither optimal nor robust. Our data-driven approach learns to control an invasive ventilator by training on a simulator itself trained on data collected from the ventilator. This method outperforms popular reinforcement learning algorithms and even controls the physical ventilator more accurately and robustly than PID. These results underscore how effective data-driven methodologies can be for invasive ventilation and suggest that more general forms of ventilation (e.g., non-invasive, adaptive) may also be amenable.","authors":"D. Suo, N. Agarwal, W. Xia, X. Chen, U. Ghai, A. Yu, P. Gradu, K. Singh, C. Zhang, E. Minasyan, J. LaChance, T. Zajdel, M. Schottdorf, D. Cohen, E. Hazan","chat_active":"","code_link":"","keywords":"optimal control","paper_link":"","poster_link":"https://drive.google.com/file/d/1GggPBUWpYQAL1WxDV8yR9Y5O-qMno3H-/view?usp=sharing","presentation_link":"","title":"Machine Learning for Mechanical Ventilation Control"}]
